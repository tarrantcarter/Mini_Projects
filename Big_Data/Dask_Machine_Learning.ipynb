{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dask_Machine_Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "crdhebieJ7OB"
      },
      "source": [
        "!pip install dask[dataframe] --upgrade --quiet\n",
        "!pip install dask-ml[complete] --quiet\n",
        "!pip install aiohttp --quiet\n",
        "!pip install joblib --quiet\n",
        "!pip install dask distributed --upgrade --quiet\n",
        "!pip install -U ipykernel --quiet\n",
        "!pip install scikit-learn==0.23.2 --quiet"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLN3Ap8XKVsT"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import dask.dataframe as dd\n",
        "import dask.array as da\n",
        "from dask.distributed import Client, progress\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_validate, GridSearchCV\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import joblib\n",
        "from dask_ml.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import dask\n",
        "import distributed\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "id": "w5KwqjeUKpc6",
        "outputId": "75c6d390-dcec-4320-a210-a267316452ee"
      },
      "source": [
        "client = Client(n_workers=4, threads_per_worker=2, memory_limit='2GB')\n",
        "client"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table style=\"border: 2px solid white;\">\n",
              "<tr>\n",
              "<td style=\"vertical-align: top; border: 0px solid white\">\n",
              "<h3 style=\"text-align: left;\">Client</h3>\n",
              "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
              "  <li><b>Scheduler: </b>tcp://127.0.0.1:39849</li>\n",
              "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
              "</ul>\n",
              "</td>\n",
              "<td style=\"vertical-align: top; border: 0px solid white\">\n",
              "<h3 style=\"text-align: left;\">Cluster</h3>\n",
              "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
              "  <li><b>Workers: </b>4</li>\n",
              "  <li><b>Cores: </b>8</li>\n",
              "  <li><b>Memory: </b>8.00 GB</li>\n",
              "</ul>\n",
              "</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<Client: 'tcp://127.0.0.1:39849' processes=4 threads=8, memory=8.00 GB>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8a16ENMUcj1L",
        "outputId": "14f317ac-50d2-4d1c-c64a-80ae9bb5e964"
      },
      "source": [
        "dask.__version__"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2021.01.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZKR9KzjTc3Nz",
        "outputId": "f1eec544-d7ab-47bc-9a09-957d6aa1b124"
      },
      "source": [
        "distributed.__version__"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2021.01.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "wSK5SWQiK0Tu",
        "outputId": "e75185c2-af11-4221-9f1a-3bb03637670c"
      },
      "source": [
        "# This loads the data into a Dask DataFrame\n",
        "df = dd.read_csv('https://tf-assets-prod.s3.amazonaws.com/tf-curric/data-science/creditcard.csv', dtype={'Time': 'float64'})\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0   0.0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62      0\n",
              "1   0.0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69      0\n",
              "2   1.0 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66      0\n",
              "3   1.0 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50      0\n",
              "4   2.0 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "WuOQgDlwLRJX",
        "outputId": "7707f7ff-a4de-417e-b14b-6369f7dc4f23"
      },
      "source": [
        "df.describe().compute()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>284807.000000</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>284807.000000</td>\n",
              "      <td>284807.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>94813.859575</td>\n",
              "      <td>1.175161e-15</td>\n",
              "      <td>3.384974e-16</td>\n",
              "      <td>-1.341216e-15</td>\n",
              "      <td>2.088465e-15</td>\n",
              "      <td>9.707851e-16</td>\n",
              "      <td>1.494498e-15</td>\n",
              "      <td>-5.652268e-16</td>\n",
              "      <td>1.143626e-16</td>\n",
              "      <td>-2.409599e-15</td>\n",
              "      <td>2.236957e-15</td>\n",
              "      <td>1.679714e-15</td>\n",
              "      <td>-1.245415e-15</td>\n",
              "      <td>8.206966e-16</td>\n",
              "      <td>1.200708e-15</td>\n",
              "      <td>4.885859e-15</td>\n",
              "      <td>1.437017e-15</td>\n",
              "      <td>-3.784146e-16</td>\n",
              "      <td>9.596083e-16</td>\n",
              "      <td>1.037048e-15</td>\n",
              "      <td>6.402711e-16</td>\n",
              "      <td>1.640595e-16</td>\n",
              "      <td>-3.544643e-16</td>\n",
              "      <td>2.610582e-16</td>\n",
              "      <td>4.473116e-15</td>\n",
              "      <td>5.205196e-16</td>\n",
              "      <td>1.687298e-15</td>\n",
              "      <td>-3.666889e-16</td>\n",
              "      <td>-1.219469e-16</td>\n",
              "      <td>88.349619</td>\n",
              "      <td>0.001727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>47488.145955</td>\n",
              "      <td>1.958696e+00</td>\n",
              "      <td>1.651309e+00</td>\n",
              "      <td>1.516255e+00</td>\n",
              "      <td>1.415869e+00</td>\n",
              "      <td>1.380247e+00</td>\n",
              "      <td>1.332271e+00</td>\n",
              "      <td>1.237094e+00</td>\n",
              "      <td>1.194353e+00</td>\n",
              "      <td>1.098632e+00</td>\n",
              "      <td>1.088850e+00</td>\n",
              "      <td>1.020713e+00</td>\n",
              "      <td>9.992014e-01</td>\n",
              "      <td>9.952742e-01</td>\n",
              "      <td>9.585956e-01</td>\n",
              "      <td>9.153160e-01</td>\n",
              "      <td>8.762529e-01</td>\n",
              "      <td>8.493371e-01</td>\n",
              "      <td>8.381762e-01</td>\n",
              "      <td>8.140405e-01</td>\n",
              "      <td>7.709250e-01</td>\n",
              "      <td>7.345240e-01</td>\n",
              "      <td>7.257016e-01</td>\n",
              "      <td>6.244603e-01</td>\n",
              "      <td>6.056471e-01</td>\n",
              "      <td>5.212781e-01</td>\n",
              "      <td>4.822270e-01</td>\n",
              "      <td>4.036325e-01</td>\n",
              "      <td>3.300833e-01</td>\n",
              "      <td>250.120109</td>\n",
              "      <td>0.041527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.640751e+01</td>\n",
              "      <td>-7.271573e+01</td>\n",
              "      <td>-4.832559e+01</td>\n",
              "      <td>-5.683171e+00</td>\n",
              "      <td>-1.137433e+02</td>\n",
              "      <td>-2.616051e+01</td>\n",
              "      <td>-4.355724e+01</td>\n",
              "      <td>-7.321672e+01</td>\n",
              "      <td>-1.343407e+01</td>\n",
              "      <td>-2.458826e+01</td>\n",
              "      <td>-4.797473e+00</td>\n",
              "      <td>-1.868371e+01</td>\n",
              "      <td>-5.791881e+00</td>\n",
              "      <td>-1.921433e+01</td>\n",
              "      <td>-4.498945e+00</td>\n",
              "      <td>-1.412985e+01</td>\n",
              "      <td>-2.516280e+01</td>\n",
              "      <td>-9.498746e+00</td>\n",
              "      <td>-7.213527e+00</td>\n",
              "      <td>-5.449772e+01</td>\n",
              "      <td>-3.483038e+01</td>\n",
              "      <td>-1.093314e+01</td>\n",
              "      <td>-4.480774e+01</td>\n",
              "      <td>-2.836627e+00</td>\n",
              "      <td>-1.029540e+01</td>\n",
              "      <td>-2.604551e+00</td>\n",
              "      <td>-2.256568e+01</td>\n",
              "      <td>-1.543008e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>49346.000000</td>\n",
              "      <td>-7.868600e-01</td>\n",
              "      <td>-5.536365e-01</td>\n",
              "      <td>-7.156553e-01</td>\n",
              "      <td>-7.067841e-01</td>\n",
              "      <td>-4.093779e-01</td>\n",
              "      <td>-6.546632e-01</td>\n",
              "      <td>-4.787135e-01</td>\n",
              "      <td>-1.339191e-01</td>\n",
              "      <td>-5.477089e-01</td>\n",
              "      <td>-4.837668e-01</td>\n",
              "      <td>-5.417076e-01</td>\n",
              "      <td>-2.351421e-01</td>\n",
              "      <td>-6.201901e-01</td>\n",
              "      <td>-3.439514e-01</td>\n",
              "      <td>-3.409833e-01</td>\n",
              "      <td>-4.198368e-01</td>\n",
              "      <td>-4.071982e-01</td>\n",
              "      <td>-4.129756e-01</td>\n",
              "      <td>-3.581993e-01</td>\n",
              "      <td>-1.686500e-01</td>\n",
              "      <td>-2.256367e-01</td>\n",
              "      <td>-5.250530e-01</td>\n",
              "      <td>-1.301482e-01</td>\n",
              "      <td>-3.241623e-01</td>\n",
              "      <td>-2.218416e-01</td>\n",
              "      <td>-2.821043e-01</td>\n",
              "      <td>-6.089022e-02</td>\n",
              "      <td>-2.762231e-02</td>\n",
              "      <td>6.840000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>76029.000000</td>\n",
              "      <td>9.301532e-02</td>\n",
              "      <td>8.999754e-02</td>\n",
              "      <td>1.743346e-01</td>\n",
              "      <td>1.809941e-01</td>\n",
              "      <td>1.480477e-01</td>\n",
              "      <td>-1.649056e-01</td>\n",
              "      <td>1.590763e-01</td>\n",
              "      <td>7.790153e-02</td>\n",
              "      <td>2.583745e-02</td>\n",
              "      <td>-9.153580e-02</td>\n",
              "      <td>1.428546e-01</td>\n",
              "      <td>2.220066e-01</td>\n",
              "      <td>5.421844e-03</td>\n",
              "      <td>6.496143e-02</td>\n",
              "      <td>3.185520e-01</td>\n",
              "      <td>8.990400e-02</td>\n",
              "      <td>-1.179887e-02</td>\n",
              "      <td>8.393824e-02</td>\n",
              "      <td>3.469481e-02</td>\n",
              "      <td>-2.513490e-02</td>\n",
              "      <td>6.636310e-03</td>\n",
              "      <td>1.241855e-01</td>\n",
              "      <td>5.160336e-02</td>\n",
              "      <td>6.794774e-02</td>\n",
              "      <td>1.674311e-01</td>\n",
              "      <td>-1.290092e-03</td>\n",
              "      <td>1.088230e-02</td>\n",
              "      <td>2.345040e-02</td>\n",
              "      <td>24.990000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>138472.000000</td>\n",
              "      <td>1.912886e+00</td>\n",
              "      <td>8.916958e-01</td>\n",
              "      <td>1.373682e+00</td>\n",
              "      <td>1.012508e+00</td>\n",
              "      <td>8.613822e-01</td>\n",
              "      <td>4.775488e-01</td>\n",
              "      <td>7.334868e-01</td>\n",
              "      <td>3.706835e-01</td>\n",
              "      <td>7.092123e-01</td>\n",
              "      <td>4.814288e-01</td>\n",
              "      <td>1.041840e+00</td>\n",
              "      <td>6.508526e-01</td>\n",
              "      <td>6.986651e-01</td>\n",
              "      <td>5.466114e-01</td>\n",
              "      <td>8.783822e-01</td>\n",
              "      <td>5.405436e-01</td>\n",
              "      <td>4.455337e-01</td>\n",
              "      <td>5.905041e-01</td>\n",
              "      <td>4.781289e-01</td>\n",
              "      <td>1.678982e-01</td>\n",
              "      <td>2.385322e-01</td>\n",
              "      <td>7.308589e-01</td>\n",
              "      <td>2.346538e-01</td>\n",
              "      <td>5.274699e-01</td>\n",
              "      <td>4.190202e-01</td>\n",
              "      <td>2.938470e-01</td>\n",
              "      <td>1.060637e-01</td>\n",
              "      <td>8.061929e-02</td>\n",
              "      <td>84.910000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>172792.000000</td>\n",
              "      <td>2.454930e+00</td>\n",
              "      <td>2.205773e+01</td>\n",
              "      <td>9.382558e+00</td>\n",
              "      <td>1.687534e+01</td>\n",
              "      <td>3.480167e+01</td>\n",
              "      <td>7.330163e+01</td>\n",
              "      <td>1.205895e+02</td>\n",
              "      <td>2.000721e+01</td>\n",
              "      <td>1.559499e+01</td>\n",
              "      <td>2.374514e+01</td>\n",
              "      <td>1.201891e+01</td>\n",
              "      <td>7.848392e+00</td>\n",
              "      <td>7.126883e+00</td>\n",
              "      <td>1.052677e+01</td>\n",
              "      <td>8.877742e+00</td>\n",
              "      <td>1.731511e+01</td>\n",
              "      <td>9.253526e+00</td>\n",
              "      <td>5.041069e+00</td>\n",
              "      <td>5.591971e+00</td>\n",
              "      <td>3.942090e+01</td>\n",
              "      <td>2.720284e+01</td>\n",
              "      <td>1.050309e+01</td>\n",
              "      <td>2.252841e+01</td>\n",
              "      <td>4.584549e+00</td>\n",
              "      <td>7.519589e+00</td>\n",
              "      <td>3.517346e+00</td>\n",
              "      <td>3.161220e+01</td>\n",
              "      <td>3.384781e+01</td>\n",
              "      <td>25691.160000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Time            V1  ...         Amount          Class\n",
              "count  284807.000000  2.848070e+05  ...  284807.000000  284807.000000\n",
              "mean    94813.859575  1.175161e-15  ...      88.349619       0.001727\n",
              "std     47488.145955  1.958696e+00  ...     250.120109       0.041527\n",
              "min         0.000000 -5.640751e+01  ...       0.000000       0.000000\n",
              "25%     49346.000000 -7.868600e-01  ...       6.840000       0.000000\n",
              "50%     76029.000000  9.301532e-02  ...      24.990000       0.000000\n",
              "75%    138472.000000  1.912886e+00  ...      84.910000       0.000000\n",
              "max    172792.000000  2.454930e+00  ...   25691.160000       1.000000\n",
              "\n",
              "[8 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKShA0oGPJTl",
        "outputId": "a7a2569a-d24d-46dd-f7e3-e59411e5a521"
      },
      "source": [
        "# This is the feature set\n",
        "X = df[[\"V1\", \"V2\", \"V3\", \"Amount\"]]\n",
        "\n",
        "# This is the target variable\n",
        "Y = df[\"Class\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
        "\n",
        "# Because your data can fit into memory,\n",
        "# persist it to the RAM\n",
        "X_train.persist()\n",
        "X_test.persist()\n",
        "y_train.persist()\n",
        "y_test.persist()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dask Series Structure:\n",
              "npartitions=3\n",
              "    int64\n",
              "      ...\n",
              "      ...\n",
              "      ...\n",
              "Name: Class, dtype: int64\n",
              "Dask Name: split, 3 tasks"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pC-Qe7RyPJ8e",
        "outputId": "b541e167-1499-4f2d-a499-acaf61783c8a"
      },
      "source": [
        "rf_model = RandomForestClassifier()\n",
        "\n",
        "with joblib.parallel_backend('dask'):\n",
        "    scores = cross_validate(rf_model, X_train.compute(), y_train.compute(), cv=4)\n",
        "    \n",
        "scores"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': array([21.85528779, 56.67017007, 57.06225014, 54.48151708]),\n",
              " 'score_time': array([0.12155294, 0.21826673, 0.2184217 , 0.21860576]),\n",
              " 'test_score': array([0.99756123, 0.99835073, 0.99875428, 0.99854373])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aj4hshFIPTbJ"
      },
      "source": [
        "# Random forest classifier\n",
        "rf_params = {\"max_depth\": [2, 4, 8, 16]}\n",
        "\n",
        "rf_model = RandomForestClassifier()\n",
        "\n",
        "grid_search_rf = GridSearchCV(rf_model,\n",
        "                           param_grid=rf_params,\n",
        "                           return_train_score=True,\n",
        "                           iid=True,\n",
        "                           cv=4,\n",
        "                           n_jobs=-1, \n",
        "                           scoring='roc_auc')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpwyiPhzPaqa"
      },
      "source": [
        "with joblib.parallel_backend('dask'):\n",
        "    grid_search_rf.fit(X_train.compute(), y_train.compute())"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_Ax-643PbQm",
        "outputId": "fa54d4a5-156b-4071-a242-f1e2d8b2e590"
      },
      "source": [
        "print(\"The best value is: \", grid_search_rf.best_params_)\n",
        "print(\"The test AUC score is: \", grid_search_rf.score(X_test.compute(), y_test.compute()))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The best value is:  {'max_depth': 8}\n",
            "The test AUC score is:  0.919151789203928\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0WEjNvmPigt",
        "outputId": "fd837b25-4e69-43c5-c516-4771ec4dbb99"
      },
      "source": [
        "from dask_ml.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression()\n",
        "\n",
        "lr.fit(X_train.values.compute(), y_train.values.compute())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdJxk6hSPmF5",
        "outputId": "1adc42c1-6e09-4cc8-ca70-fd750d5c72ab"
      },
      "source": [
        "preds_train = lr.predict(X_train.values.compute())\n",
        "preds_test = lr.predict(X_test.values.compute())\n",
        "\n",
        "print(\"Training score is: \", roc_auc_score(preds_train, y_train.values.compute()))\n",
        "print(\"Test score is: \", roc_auc_score(preds_test, y_test.values.compute()))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training score is:  0.8433109683308756\n",
            "Test score is:  0.7108254333694475\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elJCAY28PrLi"
      },
      "source": [
        "## In this task, you'll train several machine-learning models from scikit-learn, using Dask as the backend of joblib. This time, you need to use all of the variables except Class as your feature set. The Class variable will be your target variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01GAu1ecPunZ",
        "outputId": "b3a117c8-33ca-4051-89a4-18842bff5bbf"
      },
      "source": [
        "# use all features, but drop target\n",
        "X = df.drop('Class',axis=1)\n",
        "\n",
        "# This is the target variable\n",
        "y = df[\"Class\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Because your data can fit into memory,\n",
        "# persist it to the RAM\n",
        "X_train.persist()\n",
        "X_test.persist()\n",
        "y_train.persist()\n",
        "y_test.persist()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dask Series Structure:\n",
              "npartitions=3\n",
              "    int64\n",
              "      ...\n",
              "      ...\n",
              "      ...\n",
              "Name: Class, dtype: int64\n",
              "Dask Name: split, 3 tasks"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ks_vSQgJ0SsA",
        "outputId": "6db8d6b4-055c-4a71-d7a3-d86c4d63e0f7"
      },
      "source": [
        "lr = LogisticRegression(fit_intercept=False)\n",
        "\n",
        "with joblib.parallel_backend('dask'):\n",
        "    lr.fit(X_train.compute(), y_train.compute())\n",
        "    \n",
        "preds_train = lr.predict(X_train.values.compute())\n",
        "preds_test = lr.predict(X_test.values.compute())\n",
        "\n",
        "print(\"Logistic regression training score is: \", roc_auc_score(preds_train, y_train.values.compute()))\n",
        "print(\"Logistic regression test score is: \", roc_auc_score(preds_test, y_test.values.compute()))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic regression training score is:  0.8338801703406193\n",
            "Logistic regression test score is:  0.831027723834703\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-NoURKgQi2z",
        "outputId": "9efed289-4d4b-487c-8756-35d70e50ab0e"
      },
      "source": [
        "rfc = RandomForestClassifier()\n",
        "\n",
        "with joblib.parallel_backend('dask'):\n",
        "    rfc.fit(X_train.compute(), y_train.compute())\n",
        "    \n",
        "preds_train = rfc.predict(X_train.values.compute())\n",
        "preds_test = rfc.predict(X_test.values.compute())\n",
        "\n",
        "print(\"Random forest training score is: \", roc_auc_score(preds_train, y_train.values.compute()))\n",
        "print(\"Random forest test score is: \", roc_auc_score(preds_test, y_test.values.compute()))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random forest training score is:  1.0\n",
            "Random forest test score is:  0.9850928681501826\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3n2qcALKzGHo",
        "outputId": "feef0a78-c8ba-4c80-8614-3017461af840"
      },
      "source": [
        "gbc = GradientBoostingClassifier()\n",
        "\n",
        "with joblib.parallel_backend('dask'):\n",
        "    gbc.fit(X_train.compute(), y_train.compute())\n",
        "    \n",
        "preds_train = gbc.predict(X_train.values.compute())\n",
        "preds_test = gbc.predict(X_test.values.compute())\n",
        "\n",
        "print(\"Gradient boosting tree training score is: \", roc_auc_score(preds_train, y_train.values.compute()))\n",
        "print(\"Gradient boosting tree test score is: \", roc_auc_score(preds_test, y_test.values.compute()))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gradient boosting tree training score is:  0.9447045595837774\n",
            "Gradient boosting tree test score is:  0.9239536850701433\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4dZhyu0PvDI"
      },
      "source": [
        "## Compare the results of your models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdB4-7UoPxhH"
      },
      "source": [
        "The random forest model performs best on the test data, even tough it is over-fitting. Logistic Regression performs the worst of the 3 models. \n",
        "\n",
        "It would be interesting to see how these models do with hyperparameter tuning. We used the default parameters for this project. In the future it would be nice to see which tuned model does best. "
      ]
    }
  ]
}